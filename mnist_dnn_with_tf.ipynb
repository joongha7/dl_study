{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_dnn_with_tf.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKaCOqQcSEe-"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWjGGkUzTEhY"
      },
      "source": [
        "# mnist data download \n",
        "# keras 라이브러리를 통해 다양한 데이터 셋을 활용할 수 있음\n",
        "# keras 라이브러리에서 mnist 데이터 셋을 가져옴 \n",
        "# x_train에는 (60000, 28, 28)의 데이터 셋이 있고, y_train에는 레이블 데이터가 담겨 있음(0~9) \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdWq0KReTsJu"
      },
      "source": [
        "# visualization\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ls7JS7gVcs2"
      },
      "source": [
        "# flatten x train data \n",
        "# reshape 함수\n",
        "# numpy 의 배열과 차원을 변형해주는 함수\n",
        "# np.reshape(변경할 배열, 차원) or 배열.reshape(차원) 으로 사용할 수 있음\n",
        "flatten_x_train = x_train.reshape(60000, 28*28)\n",
        "\n",
        "# change data to onehot vector \n",
        "# to_categorical 함수\n",
        "# keras.utils.np_utils 패키지에 있는 to_categorical 함수는 바로 One-hot 인코딩을 해주는 함수\n",
        "# One-hot 인코딩이랑 10진 정수 형식을 특수한 2진 바이너리 형식으로 변경하는 것이다.\n",
        "# 파라미터로 값에 크기만큼 0으로 된 배열을 만들고, 파라미터 값 위치에만 1(hot)을 넣어준다.\n",
        "# EX) array([1,2,3]) => array([[1,0,0], [0,1,0], [0,0,1]])\n",
        "y_train_onehot = to_categorical(y_train, 10)\n",
        "\n",
        "# flatten x test data \n",
        "flatten_x_test = x_test.reshape(10000, 28*28)\n",
        "\n",
        "# change data to onehot vector \n",
        "y_test_onehot = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAcHF_xXlq3"
      },
      "source": [
        "# Input layer \n",
        "# Input() 은 텐서를 인스턴스화 하는데 사용됨\n",
        "# 입력 데이터의 크기를 인자로 입력층에 정의\n",
        "inputs = Input(shape=(28*28))\n",
        "\n",
        "# hidden layer \n",
        "\n",
        "# Dense : Neural Network를 구성하는 layer를 생성하는데 필요\n",
        "# units : Dense를 통해서 만들 hidden layer의 노드 수를 정의하는 것\n",
        "#  - Input Layer 에서 Hidden Layer로 넘어갈 때의 시냅스의 수를 적절히 조절하거나,\n",
        "#  - Hidden layer의 개수를 정의하는 것은 전체 Neural Network의 성능을 크게 좌우할 수 있음.\n",
        "#  => Parameter tuning\n",
        "# kernel_initializer : data 셋의 구성에 따라 사용\n",
        "\n",
        "# Stochastic Gradient Descent(SGD) : Cost Function 을 Minimize 시키는 방법 중 하나로\n",
        "# 전체 데이터 셋이 아닌 잘게 쪼개 학습시키는 방식\n",
        "\n",
        "# 다층 퍼셉트론\n",
        "# 가장 기본적인 형태의 인공 신경망(Artificial Neural Networks) 구조\n",
        "# 하나의 Input layer, 하나 이상의 Hidden layer, 하나의 Output layer로 구성됨\n",
        "\n",
        "# ReLu : Rectified Linear Unit\n",
        "# Sigmoid 함수를 ReLu 가 대체하게 된 이유는 Gradient Vanishing 문제 때문임\n",
        "# Sigmoid 함수는 0~1 사이의 값을 가지게 되는데, gradient descent를 사용해 Backpropagation 수행시\n",
        "# Layer를 지나면서 gradient는 0으로 수렴하게 됨, layer수가 많아지면 잘 동작하지 않음\n",
        "# 이런 문제를 해결하기 위해 ReLu라는 activation function을 사용한다.\n",
        "# (x < 0) f(x) = 0\n",
        "# (x >= 0) f(x) = x\n",
        "\n",
        "# he_normal\n",
        "# 0을 중심으로 stddev = sqrt(2/fan_in)의 표준편차를 가진 절단된 정규분포에 따라 샘플이 생성됨\n",
        "# (fan_in 이란 가중치 텐서의 입력 유닛 수)\n",
        "layer_1 = Dense(units=128, activation='relu', kernel_initializer='he_normal')(inputs)\n",
        "layer_2 = Dense(units=128, activation='relu', kernel_initializer='he_normal')(layer_1)\n",
        "\n",
        "# output layer \n",
        "# Softmax Regression (다중 클래스 분려ayer_2 = Dense(units=128, activation='relu', kernel_initializer='he_normal')(layer_1)\n",
        "\n",
        "# output layer \n",
        "# Softmax Regression (다중 클래스 분류)\n",
        "# 소프트 맥스 함수는 분류해야하는 정답지(클래스)의 총 개수를 k라고 할 때,\n",
        "# k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정한다.\n",
        "# 개념 설명 필요\n",
        "\n",
        "# glorot_normal : Xavier 정규분포 초기값 설정기\n",
        "# 0을 중심으로 stddev = sqrt(2 / (fan_in + fan_out))의 표준편차를 가진 절단된 정규분포에 따라 샘플이 생성됨\n",
        "# fan_in이란 가중치 텐서의 입력 유닛의 수, fan_out은 가중치 텐서의 출력 유닛의 수를 의미함\n",
        "outputs = Dense(units=10, activation='softmax', kernel_initializer='glorot_normal')(layer_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcxNc01Ib_nH"
      },
      "source": [
        "y_test.shape, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hjQRRYZc4o"
      },
      "source": [
        "# Model\n",
        "model = Model(inputs, outputs)\n",
        "# Model 을 학습하는 방법\n",
        "# 모델을 학습시키기 전에 compile 메소드를 통해서 학습 방식에 대한 환경 설정을 해야함.\n",
        "\n",
        "# categorical_crossentropy\n",
        "# 다중 분류 손실 함수 \n",
        "# 출력 값이 one-hot encoding된 결과로 나옴\n",
        "# 클래스가 상호 배타적일 경우 사용\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "# 다중 분류 손실 함수\n",
        "# integer type 클래스 -> one-hot encoding 하지 않고 정수 형태로 label을 넣어줌\n",
        "# 한 샘플에 여러 클래스가 있거나 label이 soft 확률일 경우 사용\n",
        "\n",
        "# binary_crossentropy\n",
        "# 바이너리 다중 분류 손실 함수\n",
        "# label들이 독립적일 때 사용arse_categorical_crossentropy\n",
        "# 다중 분류 손실 함수\n",
        "# integer type 클래스 -> one-hot encoding 하지 않고 정수 형태로 label을 넣어줌\n",
        "# 한 샘플에 여러 클래스가 있거나 label이 soft 확률일 경우 사용\n",
        "\n",
        "# binary_crossentropy\n",
        "# 바이너리 다중 분류 손실 함수\n",
        "# label들이 독립적일 때 사용\n",
        "\n",
        "# Optimizer\n",
        "# adam(Adaptive Momentum estimation) \n",
        "# Adagrad와 momentum의 결합\n",
        "model.compile('adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.compile('adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9w2sS0HaUEI"
      },
      "source": [
        "# 모델 \n",
        "model.fit(x=flatten_x_train, y=y_train_onehot, \n",
        "          validation_data=(flatten_x_test, y_test_onehot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIZjGLVWdeyo"
      },
      "source": [
        "# 훈련된 모델을 사용하여 이미지에 대한 예측을 만들 수 있음\n",
        "# 예측은 숫자 배열로 나타나고 이는 모델의 신뢰도(Confidence)를 나타냄 \n",
        "test_pred = model.predict(flatten_x_test)\n",
        "# test_pred.shape\n",
        "\n",
        "# numpy argmax : 다차원 배열의 경우에 차원에 따라 가장 큰 값의 인덱스들을 반환해 주는 함수\n",
        "test_cls = np.argmax(test_pred, axis=1)\n",
        "# test_cls\n",
        "\n",
        "# plt.imshow(x_test[0])\n",
        "# test_cls[0]\n",
        "\n",
        "plt.imshow(x_test[2])\n",
        "test_cls[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GWFXdqJK9Aw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpTDxYdpK9MT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aotoqV_8K9Wf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmpgC8k3K9e8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcaJ54JJX452"
      },
      "source": [
        "class A()\n",
        "    # constructor : magic method\n",
        "    def __init__(self, )\n",
        "\n",
        "    # call function : magic method \n",
        "    def __call__(self, a)\n",
        "\n",
        "A()()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}